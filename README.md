### README
<p align="center">
  <a href="https://www.uit.edu.vn/"><img src="https://www.uit.edu.vn/sites/vi/files/banner.png"></a>
<h1 align="center"><b>CS519.O21.KHTN - Scientific Research Methodology</b></h1>

# Project Title: ÁP DỤNG TRÍ TUỆ NHÂN TẠO CÓ THỂ GIẢI THÍCH VÀ THÍCH ỨNG MIỀN CHO CHẨN ĐOÁN VÀ ĐIỀU TRỊ TRONG HỆ THỐNG Y TẾ LIÊN KẾT

## English Title: APPLICATION OF EXPLAINABLE ARTIFICIAL INTELLIGENCE (XAI) AND DOMAIN-ADAPTATION (DA) FOR DIAGNOSIS AND TREATMENT IN FEDERATED LEARNING-BASED HEALTHCARE SYSTEM

## Overview

This project focuses on improving healthcare diagnosis and treatment through the application of Explainable Artificial Intelligence (XAI) and Domain Adaptation (DA) in a Federated Learning (FL) based system. The primary aim is to enhance the accuracy, reliability, and transparency of machine learning models in medical applications while maintaining data privacy.

## Objectives

1. **Enhance Domain Adaptation (DA) in healthcare:** Improve the performance of machine learning models on new and unseen medical data by addressing domain shifts.
2. **Develop and apply Explainable AI (XAI) in healthcare:** Ensure AI models are transparent and interpretable, fostering trust among healthcare professionals.
3. **Advance AI applications in medical research and healthcare:** Support early disease detection, accurate diagnosis, and prognosis prediction through innovative AI solutions.

## Content and Methods

### Content 1: Foundation and Related Work
- Survey and analyze existing research on domain shift and XAI in FL.
- Evaluate the impact of domain shift on FL model performance.
- Experiment with XAI techniques to explain and improve FL models under domain shift conditions.

### Content 2: Design DA Methods for Federated Healthcare Systems
- Review relevant literature and integrate findings.
- Implement FL models with DA to address domain shift issues effectively.

### Content 3: Develop XAI Methods for Federated Learning in Healthcare
- Enhance the transparency and interpretability of AI models in healthcare.
- Develop AI models capable of explaining their decisions, thereby increasing trust and acceptance among healthcare professionals.

### Content 4: System Implementation and Experimentation
- Build an AI model capable of adapting to domain changes without manual intervention.
- Ensure the AI model can provide transparent and understandable decisions.
- Test the model's performance in various real-world scenarios to ensure its robustness and reliability.

## Expected Results
- Comprehensive documentation on applying XAI and DA in FL-based healthcare models.
- Detailed evaluation of model performance on different datasets, including accuracy and reliability assessments.
- Empirical evidence showcasing the model's ability to explain its decisions in practical healthcare scenarios.

## Project Files

- **Proposal**: [Proposal.pdf](./Proposal.pdf)
- **Poster**: [Poster.pdf](./Poster.pdf)
- **Slides**: [Slides.pdf](./Slide.pdf)
- **YouTube Video**: [Project Video](https://youtu.be/I3Ne9ly2sJY)
- **GitHub Repository**: [Project Repository](https://github.com/chauthevi2004/CS519.O21.KHTN)

## Author Information
- **Name**: Châu Thế Vĩ - 22521653@gm.uit.edu.vn
- **Student ID**: 22521653
- **Lecturer**: Associate Professor Dr. Lê Đình Duy - duyld@uit.edu.vn
- **Class**: CS519.O21.KHTN

## References
- For a detailed list of references used in this project, please refer to the "Proposal.pdf" file.

This README provides a comprehensive overview of the project, highlighting the key aspects of the research and implementation process. For further details, please refer to the attached proposal, poster, and slides.
